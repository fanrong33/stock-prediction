# encoding: utf-8
""" é¢„æµ‹è‚¡ç¥¨ä»·æ ¼

@version 1.0.2 build 20180613
"""

from __future__ import print_function
import os
import argparse
import torch
from torch.autograd import Variable

import numpy as np
import pandas as pd
from sklearn.externals import joblib
import matplotlib.pyplot as plt

from models import RNN

plt.rcParams['font.sans-serif'] = ['SimHei'] # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾
plt.rcParams['axes.unicode_minus'] = False # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·


parser = argparse.ArgumentParser(description='Pytorch Time Sequence Perdicton')
parser.add_argument('--input', default='input/', help='path to dataset')
parser.add_argument('--lr', type=float, default=0.01, metavar='LR', help='learning rate (default: 0.01)')
parser.add_argument('--output', default='saves/', help='folder to output images and model checkpoints')
parser.add_argument('--epochs', type=int, default=8, metavar='EPOCHS', help='number of epochs to train (default: 8)')

args = parser.parse_args()



# Hyper Parameters
# HIDDEN_SIZE è°ƒæ•´ä¸º100ã€200ï¼Œæˆ– NUM_LAYERS è°ƒæ•´ä¸º 2ï¼Œä¸æ˜ç™½ä¸ºä»€ä¹ˆå§‹ç»ˆæ— æ³•æ‹Ÿåˆâ”ğŸ˜“
TIME_STEP = 1
INPUT_SIZE = 60
HIDDEN_SIZE = 50
NUM_LAYERS = 1
OUTPUT_SIZE = 1


# åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
rnn = RNN(INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS, OUTPUT_SIZE)

rnn_state_dict = torch.load('%s/time_series_rnn_model_params.pkl' % args.output)
rnn.load_state_dict(rnn_state_dict)



# å¾ªç¯é¢„æµ‹æ¥ä¸‹æ¥çš„æ•°æ®
''' sample ç¤ºä¾‹
 1 2 3 4 5 6 7 8 9 10   --- predict ---> 11 12 13 14 15
 train[-5:]
         |          |
          --inputs--
'''
# åŠ è½½é¢„å¤„ç†è¿‡ï¼ˆæ­£åˆ™åŒ–ï¼‰çš„è®­ç»ƒæ•°æ®, å–æœ€åçš„æ—¶é—´åºåˆ—é¢„æµ‹æœªæ¥20å‡ å¤©
train_dataset = np.load('input/000001.XSHE_train.npy')
scaler = joblib.load('encoder/min_max_scaler.close.pkl')

# å¾ªç¯é¢„æµ‹æ¥ä¸‹æ¥çš„æ•°æ®
''' sample ç¤ºä¾‹
 1 2 3 4 5 6 7 8 9 10   --- predict ---> 11 12 13 14 15
 train[-5:]
         |          |
          --inputs--
'''
test_dataset = train_dataset[-INPUT_SIZE:]


pred_list = []
for i in range(22):  # é¢„æµ‹æœªæ¥22å¤©çš„æ•°æ®
    # Reshaping (batch, time_step, input_size)
    inputs = test_dataset.reshape(-1, 1, 60)
    inputs = Variable(torch.from_numpy(inputs).float())
    
    hidden_state = None
    output, hidden_state = rnn(inputs, hidden_state)
    predicted = output.data.numpy()
    ''' [[ 0.88910466]] '''
    
    pred_list.append(predicted[0][0])

    # åŠ å…¥æ–°é¢„æµ‹çš„ä»·æ ¼ï¼Œå»æ‰é¡¶éƒ¨ä¹‹å‰çš„ä»·æ ¼
    test_dataset = np.concatenate((test_dataset, predicted), axis=0)
    test_dataset = test_dataset[1:]

# é¢„æµ‹çš„å€¼æ˜¯[0,1]ï¼Œå°†è¯¥å€¼è½¬æ¢å›åŸå§‹å€¼
pred_list = np.reshape(pred_list, (-1, 1))
pred_list = scaler.inverse_transform(pred_list)




plt.figure(1, figsize=(12, 5))
# ç»˜åˆ¶è®­ç»ƒçš„è‚¡ä»·
plt.plot(scaler.inverse_transform(train_dataset), 'b-', label='train')

# ç»˜åˆ¶æœªæ¥è‚¡ä»·çš„çœŸå®ä»·æ ¼
test_dataset = pd.read_csv('data/000001.XSHE_test.csv')
real_stock_price = test_dataset.iloc[:, 1:2].values
plt.plot(np.arange(len(train_dataset), len(train_dataset)+len(real_stock_price)), real_stock_price.flatten(), 'g-', label='real')

# å¯è§†åŒ–é¢„æµ‹æœªæ¥å‡ å¤©çš„ä»·æ ¼
plt.plot(np.arange(len(train_dataset), len(train_dataset)+len(real_stock_price)), pred_list, 'r:', label='predict')

plt.legend(loc='best')
plt.title('å¹³å®‰é“¶è¡Œ')
plt.show()



